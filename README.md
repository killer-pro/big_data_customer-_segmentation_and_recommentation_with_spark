# big_data_customer-_segmentation_and_recommentation_with_spark

# 1. Pr√©sentation du Projet

## Contexte

Le pr√©sent projet vise √† concevoir une solution d‚Äôanalyse comportementale des utilisateurs d‚Äôune plateforme e-commerce, avec pour finalit√© l‚Äô√©laboration d‚Äôun syst√®me de recommandation intelligent. Ce projet, men√© dans un cadre acad√©mique, s‚Äôappuie sur des technologies Big Data et des approches d‚Äôintelligence artificielle afin de traiter efficacement des volumes importants de donn√©es g√©n√©r√©s par les utilisateurs.

## Objectifs du Projet

Le projet vise √† concevoir une solution compl√®te d‚Äôanalyse comportementale et de recommandation intelligente dans un contexte e-commerce. Pour cela, plusieurs objectifs principaux ont √©t√© d√©finis :

### ‚Ä¢ Compr√©hension et mod√©lisation des comportements utilisateurs

L‚Äôobjectif initial est d‚Äôanalyser en profondeur les comportements de navigation et d‚Äôachat des utilisateurs √† partir des donn√©es de logs collect√©es sur une plateforme e-commerce. Il s‚Äôagit notamment d‚Äôidentifier les actions r√©alis√©es par les utilisateurs (consultations, ajouts au panier, achats), d‚Äô√©tudier la chronologie et la fr√©quence de ces actions, et d‚Äôen extraire des tendances comportementales significatives. Ces analyses doivent permettre d‚Äô√©tablir un mod√®le repr√©sentatif des interactions typiques entre un utilisateur et la plateforme.

### ‚Ä¢ Identification des patterns d‚Äôinteractions et des profils types

√Ä partir des donn√©es collect√©es, il est essentiel d‚Äôidentifier des sch√©mas d‚Äôinteractions r√©currents, appel√©s patterns, permettant de regrouper les utilisateurs selon des comportements similaires. Cette √©tape vise √† faire √©merger des profils types de clients (par exemple : acheteurs impulsifs, visiteurs r√©guliers non acheteurs, utilisateurs sensibles au prix, etc.), facilitant ainsi une segmentation fine de la client√®le et une personnalisation plus pertinente des actions marketing ou commerciales.

### ‚Ä¢ Mise en place d‚Äôun syst√®me de recommandation dynamique et personnalis√©

Sur la base des pr√©f√©rences observ√©es (historique de navigation, fr√©quence d‚Äôachat, cat√©gories pr√©f√©r√©es, marques consult√©es), un syst√®me de recommandation doit √™tre d√©velopp√©. Ce syst√®me devra √™tre capable de proposer de mani√®re dynamique des produits pertinents √† chaque utilisateur, en tenant compte √† la fois de ses habitudes pass√©es et de son profil comportemental. Les recommandations devront s‚Äôappuyer sur des techniques hybrides combinant filtrage collaboratif, analyse de contenu, et segmentation client.

### ‚Ä¢ Simulation d‚Äôun environnement temps r√©el pour √©valuation des performances

Enfin, une infrastructure de simulation en temps r√©el sera mise en place afin de tester la robustesse et la r√©activit√© de l‚Äôensemble du syst√®me. Cette simulation permettra de reproduire l‚Äôarriv√©e continue des donn√©es, de d√©clencher le traitement de ces flux par les modules analytiques et de mesurer les performances en conditions quasi-r√©elles.

## Donn√©es

Les jeux de donn√©es fournis sont au format CSV et couvrent les √©v√©nements de navigation et d‚Äôachat sur les mois d‚Äôoctobre et novembre. Chaque enregistrement contient des informations sur le type d‚Äô√©v√©nement, les produits concern√©s, les cat√©gories, la marque, le prix, l‚Äôutilisateur et sa session. Le volume de donn√©es est estim√© √† plusieurs dizaines de millions de lignes, ce qui justifie l‚Äôadoption d‚Äôune architecture Big Data.

---

# 2. Architecture Technique

## Infrastructure

L‚Äôenvironnement repose sur une machine locale Windows (8 √† 16 Go RAM). Apache Spark (mode local avec PySpark) assure le traitement. Les donn√©es sont stock√©es localement dans un HDFS simul√©. InfluxDB est utilis√© pour les m√©triques, visualis√©es via Grafana.

## Sch√©ma architectural

Les fichiers CSV sont ing√©r√©s dans HDFS, trait√©s via Spark, puis les r√©sultats sont stock√©s dans InfluxDB et visualis√©s dans Grafana. Les mod√®les ML sont entra√Æn√©s et mis √† jour en parall√®le, avec un stockage interm√©diaire pour faciliter les analyses.

---

# 3. Sp√©cifications Fonctionnelles

## Analyse comportementale

Identification des s√©quences typiques et g√©n√©ration d‚Äôindicateurs (fr√©quence de visite, dur√©e des sessions, taux de conversion, etc.).

## Segmentation client

Initialement r√©alis√©e avec K-means sur les donn√©es d‚Äôoctobre, puis affin√©e via l‚Äôanalyse RFM. Mise √† jour incr√©mentale avec les donn√©es de novembre.

## Syst√®me de recommandation

Techniques hybrides combinant :
- Filtrage collaboratif (ALS)
- Analyse de contenu (TF-IDF, similarit√© cosinus)
- Pond√©ration bas√©e sur le segment client

## Simulation temps r√©el

Injection des donn√©es en micro-lots dans Spark Streaming toutes les 10s. Mise √† jour continue des mod√®les et enregistrement dans InfluxDB.

---

# 4. Sp√©cifications Techniques

## Spark

- Mode standalone local
- Parall√©lisme : 4 c≈ìurs min
- M√©moire : jusqu‚Äô√† 16 Go
- Checkpointing activ√© pour le streaming

## Structure des donn√©es

- `/data/raw/` : donn√©es brutes  
- `/data/processed/` : donn√©es nettoy√©es  
- `/data/models/` : mod√®les entra√Æn√©s  
- `/data/temp/` : r√©sultats interm√©diaires  

## Mod√®les de Machine Learning

- Entra√Æn√©s en batch sur les donn√©es d‚Äôoctobre
- Mise √† jour incr√©mentale en streaming
- Persist√©s via Spark ML

## InfluxDB & Grafana

- Stockage des m√©triques utilisateur et produit
- Tableaux de bord Grafana, actualis√©s toutes les 5s

---

# 5. Phases de D√©veloppement

Le d√©veloppement est structur√© en quatre phases cl√©s :

## üîπ Phase 1 : Pr√©paration, EDA, premiers mod√®les

- Installation et configuration des outils (Spark, Kafka, Jupyter)
- Nettoyage et normalisation des donn√©es
- EDA pour compr√©hension des donn√©es
- Mod√®les de clustering et segmentation

## üîπ Phase 2 : Simulation temps r√©el et mod√®les adaptatifs

- Pipeline d‚Äôingestion en micro-lots avec Kafka ou Spark Streaming
- Modules de traitement en flux
- Persistance des r√©sultats interm√©diaires

## üîπ Phase 3 : Int√©gration des m√©triques et dashboards

- S√©lection des indicateurs cl√©s
- Monitoring et alerting
- Cr√©ation de dashboards dynamiques (Grafana, Kibana)

## üîπ Phase 4 : Tests de charge, optimisation, finalisation

- Tests de scalabilit√©
- Optimisation (latence, ressources, pr√©cision)
- Documentation technique compl√®te
- Feedback utilisateurs et ajustements finaux
